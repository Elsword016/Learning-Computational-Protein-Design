{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Secondary Structure Prediction of protein sequences using 1D CNN \n",
    "This is a very beginner friendly notebook to understand the basics of protein secondary structure prediction using 1D CNN. I am not focusing here to optimize the model (maybe in another notebook), I want to create a small model with 1D CNN layers to predict the secondary structures of a given protein sequence typically classified as H (Helix), E (Sheet) and C (coil). \n",
    "This is an example of **sequence-to-sequence** prediction task. \n",
    "\n",
    "### Dataset Used:\n",
    "From Kaggle [Protein Secondary Structure Prediction-2022](https://www.kaggle.com/datasets/kirkdco/protein-secondary-structure-2022/data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing \n",
    "Few things we need to make sure before even going to the model building process:\n",
    "1. Verify that for every single protein entry, the length of the amino acid sequence string is identical to the length of the secondary structure label string. Discard or fix any entries where they don't match.\n",
    "2. Check unique characters in amino acid sequence string and secondary structure label string.  \n",
    "3. Non-standard amino acids and secondary structure labels should be removed or fixed. (In case there is none as indicated by `has_nonstd_aa` = `False`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdb_id</th>\n",
       "      <th>chain_code</th>\n",
       "      <th>seq</th>\n",
       "      <th>sst8</th>\n",
       "      <th>sst3</th>\n",
       "      <th>len_x</th>\n",
       "      <th>has_nonstd_aa</th>\n",
       "      <th>len_y</th>\n",
       "      <th>method</th>\n",
       "      <th>resol</th>\n",
       "      <th>rfac</th>\n",
       "      <th>freerfac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5D8V</td>\n",
       "      <td>A</td>\n",
       "      <td>AAPANAVTADDPTAIALKYNQDATKSERVAAARPGLPPEEQHCANC...</td>\n",
       "      <td>CCCTTBCCTTCHHHHHHTCBSSGGGSCHHHHCCTTSCGGGCCGGGB...</td>\n",
       "      <td>CCCCCECCCCCHHHHHHCCECCHHHCCHHHHCCCCCCHHHCCHHHE...</td>\n",
       "      <td>83</td>\n",
       "      <td>False</td>\n",
       "      <td>83</td>\n",
       "      <td>XRAY</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3NIR</td>\n",
       "      <td>A</td>\n",
       "      <td>TTCCPSIVARSNFNVCRLPGTPEALCATYTGCIIIPGATCPGDYAN</td>\n",
       "      <td>CEECSSHHHHHHHHHHHTTTCCHHHHHHHHSCEECSSSCCCTTSCC</td>\n",
       "      <td>CEECCCHHHHHHHHHHHCCCCCHHHHHHHHCCEECCCCCCCCCCCC</td>\n",
       "      <td>46</td>\n",
       "      <td>False</td>\n",
       "      <td>46</td>\n",
       "      <td>XRAY</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.127</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5NW3</td>\n",
       "      <td>A</td>\n",
       "      <td>MAKWVCKICGYIYDEDAGDPDNGISPGTKFEELPDDWVCPICGAPK...</td>\n",
       "      <td>CCEEEETTTCCEEETTTCBGGGTBCTTCCGGGSCTTCBCTTTCCBG...</td>\n",
       "      <td>CCEEEECCCCCEEECCCCEHHHCECCCCCHHHCCCCCECCCCCCEH...</td>\n",
       "      <td>54</td>\n",
       "      <td>False</td>\n",
       "      <td>54</td>\n",
       "      <td>XRAY</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pdb_id chain_code                                                seq  \\\n",
       "0   5D8V          A  AAPANAVTADDPTAIALKYNQDATKSERVAAARPGLPPEEQHCANC...   \n",
       "1   3NIR          A     TTCCPSIVARSNFNVCRLPGTPEALCATYTGCIIIPGATCPGDYAN   \n",
       "2   5NW3          A  MAKWVCKICGYIYDEDAGDPDNGISPGTKFEELPDDWVCPICGAPK...   \n",
       "\n",
       "                                                sst8  \\\n",
       "0  CCCTTBCCTTCHHHHHHTCBSSGGGSCHHHHCCTTSCGGGCCGGGB...   \n",
       "1     CEECSSHHHHHHHHHHHTTTCCHHHHHHHHSCEECSSSCCCTTSCC   \n",
       "2  CCEEEETTTCCEEETTTCBGGGTBCTTCCGGGSCTTCBCTTTCCBG...   \n",
       "\n",
       "                                                sst3  len_x  has_nonstd_aa  \\\n",
       "0  CCCCCECCCCCHHHHHHCCECCHHHCCHHHHCCCCCCHHHCCHHHE...     83          False   \n",
       "1     CEECCCHHHHHHHHHHHCCCCCHHHHHHHHCCEECCCCCCCCCCCC     46          False   \n",
       "2  CCEEEECCCCCEEECCCCEHHHCECCCCCHHHCCCCCECCCCCCEH...     54          False   \n",
       "\n",
       "   len_y method  resol   rfac  freerfac  \n",
       "0     83   XRAY   0.48  0.072     0.078  \n",
       "1     46   XRAY   0.48  0.127       NaN  \n",
       "2     54   XRAY   0.59  0.135     0.146  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"2022-12-17-pdb-intersect-pisces_pc30_r2.5.csv\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check if the seq len = sst3 \n",
    "len(df['seq']) == len(df['sst3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['has_nonstd_aa'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pdb_id', 'chain_code', 'seq', 'sst8', 'sst3', 'len_x', 'has_nonstd_aa',\n",
       "       'len_y', 'method', 'resol', 'rfac', 'freerfac'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['chain_code','sst8','len_x','len_y','has_nonstd_aa','method','resol','rfac','freerfac'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features and target variable \n",
    "1. Features are amino acid sequences `seq`.\n",
    "2. Target variable is secondary structure labels in this case we have two `sst3` and `sst8`. Here I used `sst3` (3 category secondary structure classification), this is the target output (Y). These strings ( containing 'H', 'E', 'C') represent the ground truth labels for each amino acid in the corresponding `seq` column. `sst8` is the 8 category secondary structure classification. More complex. For now I ignored it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdb_id</th>\n",
       "      <th>seq</th>\n",
       "      <th>sst3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5D8V</td>\n",
       "      <td>AAPANAVTADDPTAIALKYNQDATKSERVAAARPGLPPEEQHCANC...</td>\n",
       "      <td>CCCCCECCCCCHHHHHHCCECCHHHCCHHHHCCCCCCHHHCCHHHE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3NIR</td>\n",
       "      <td>TTCCPSIVARSNFNVCRLPGTPEALCATYTGCIIIPGATCPGDYAN</td>\n",
       "      <td>CEECCCHHHHHHHHHHHCCCCCHHHHHHHHCCEECCCCCCCCCCCC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5NW3</td>\n",
       "      <td>MAKWVCKICGYIYDEDAGDPDNGISPGTKFEELPDDWVCPICGAPK...</td>\n",
       "      <td>CCEEEECCCCCEEECCCCEHHHCECCCCCHHHCCCCCECCCCCCEH...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pdb_id                                                seq  \\\n",
       "0   5D8V  AAPANAVTADDPTAIALKYNQDATKSERVAAARPGLPPEEQHCANC...   \n",
       "1   3NIR     TTCCPSIVARSNFNVCRLPGTPEALCATYTGCIIIPGATCPGDYAN   \n",
       "2   5NW3  MAKWVCKICGYIYDEDAGDPDNGISPGTKFEELPDDWVCPICGAPK...   \n",
       "\n",
       "                                                sst3  \n",
       "0  CCCCCECCCCCHHHHHHCCECCHHHCCHHHHCCCCCCHHHCCHHHE...  \n",
       "1     CEECCCHHHHHHHHHHHCCCCCHHHHHHHHCCEECCCCCCCCCCCC  \n",
       "2  CCEEEECCCCCEEECCCCEHHHCECCCCCHHHCCCCCECCCCCCEH...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding sequences \n",
    "The most important part of the model building process is encoding the sequences and secondary structure labels.  ML models work with numbers and not strings. I used very simple encoding scheme for amino acids and secondary structure labels. \n",
    "\n",
    "I used unique integer indices for each possible character for amino acids and secondary structure labels.\n",
    "```python\n",
    "Unique amino acids: ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'X', 'Y']\n",
    "Unique secondary structure states: ['C', 'E', 'H']\n",
    "```\n",
    "Next, padding token `<PAD>` is added to the beginning of the list of amino acids and secondary structure states.  This is done to ensure that all sequences have the same length which is ncessary for batch processing in the model.   \n",
    "\n",
    "For example: \n",
    "```python\n",
    "Unique amino acids: ['<PAD>', 'A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'X', 'Y']\n",
    "Unique secondary structure states: ['<PAD>', 'C', 'E', 'H']\n",
    "```\n",
    "One sequence might have 100 length and another 150. This mismatch prevents stacking them into a single tensor. Padding is added to the shorter sequence to make it 150.  \n",
    "\n",
    "The `<PAD>` token is given its own unique integer index.  Here, i added to the first index of the list of amino acids and secondary structure states.  During model training and evaluation we tell the model to ignore this padding token.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique amino acids: ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'X', 'Y']\n",
      "Unique secondary structure states: ['C', 'E', 'H']\n"
     ]
    }
   ],
   "source": [
    "##Encoding \n",
    "seq_chars = set(\"\".join(df['seq'].tolist())) \n",
    "sst3_chars = set(\"\".join(df['sst3'].tolist())) \n",
    "print(f'Unique amino acids: {sorted(list(seq_chars))}')\n",
    "print(f'Unique secondary structure states: {sorted(list(sst3_chars))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AA Vocab Size: 22\n",
      "SST3 Vocab Size: 4\n",
      "AA PAD ID: 0\n",
      "SST3 PAD ID: 0\n"
     ]
    }
   ],
   "source": [
    "##Encoding \n",
    "aa_list = sorted(list(seq_chars))\n",
    "ss_list = sorted(list(sst3_chars)) \n",
    "\n",
    "PAD_TOKEN = '<PAD>'\n",
    "aa_list_pad = [PAD_TOKEN] + aa_list\n",
    "ss_list_pad = [PAD_TOKEN] + ss_list \n",
    "\n",
    "#creating mappings \n",
    "aa_to_idx = {aa: idx for idx, aa in enumerate(aa_list_pad)}\n",
    "ss_to_idx = {ss: idx for idx, ss in enumerate(ss_list_pad)}\n",
    "\n",
    "#reverse mappings \n",
    "aa_idx_to_aa = {idx: aa for idx, aa in enumerate(aa_list_pad)}\n",
    "ss_idx_to_ss = {idx: ss for idx, ss in enumerate(ss_list_pad)}\n",
    "\n",
    "PAD_ID_AA = aa_to_idx[PAD_TOKEN]\n",
    "PAD_ID_SS = ss_to_idx[PAD_TOKEN]\n",
    "\n",
    "print(\"AA Vocab Size:\", len(aa_list_pad))\n",
    "print(\"SST3 Vocab Size:\", len(ss_list_pad))\n",
    "print(\"AA PAD ID:\", PAD_ID_AA)\n",
    "print(\"SST3 PAD ID:\", PAD_ID_SS) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<PAD>': 0,\n",
       " 'A': 1,\n",
       " 'C': 2,\n",
       " 'D': 3,\n",
       " 'E': 4,\n",
       " 'F': 5,\n",
       " 'G': 6,\n",
       " 'H': 7,\n",
       " 'I': 8,\n",
       " 'K': 9,\n",
       " 'L': 10,\n",
       " 'M': 11,\n",
       " 'N': 12,\n",
       " 'P': 13,\n",
       " 'Q': 14,\n",
       " 'R': 15,\n",
       " 'S': 16,\n",
       " 'T': 17,\n",
       " 'V': 18,\n",
       " 'W': 19,\n",
       " 'X': 20,\n",
       " 'Y': 21}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<PAD>': 0, 'C': 1, 'E': 2, 'H': 3}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss_to_idx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add mappings \n",
    "df['seq_idx'] = df['seq'].apply(lambda x: [aa_to_idx[aa] for aa in x])\n",
    "df['ss_idx'] = df['sst3'].apply(lambda x: [ss_to_idx[ss] for ss in x]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 seq  \\\n",
      "0  AAPANAVTADDPTAIALKYNQDATKSERVAAARPGLPPEEQHCANC...   \n",
      "1     TTCCPSIVARSNFNVCRLPGTPEALCATYTGCIIIPGATCPGDYAN   \n",
      "2  MAKWVCKICGYIYDEDAGDPDNGISPGTKFEELPDDWVCPICGAPK...   \n",
      "3  NKASVVANQLIPINTALTLIMMKAEVVTPMGIPAEEIPKLVGMQVN...   \n",
      "4  ATGGYVQQATGQASFTMYSGCGSPACGKAASGFTAAINQLAFGSAP...   \n",
      "\n",
      "                                             seq_idx  \\\n",
      "0  [1, 1, 13, 1, 12, 1, 18, 17, 1, 3, 3, 13, 17, ...   \n",
      "1  [17, 17, 2, 2, 13, 16, 8, 18, 1, 15, 16, 12, 5...   \n",
      "2  [11, 1, 9, 19, 18, 2, 9, 8, 2, 6, 21, 8, 21, 3...   \n",
      "3  [12, 9, 1, 16, 18, 18, 1, 12, 14, 10, 8, 13, 8...   \n",
      "4  [1, 17, 6, 6, 21, 18, 14, 14, 1, 17, 6, 14, 1,...   \n",
      "\n",
      "                                                sst3  \\\n",
      "0  CCCCCECCCCCHHHHHHCCECCHHHCCHHHHCCCCCCHHHCCHHHE...   \n",
      "1     CEECCCHHHHHHHHHHHCCCCCHHHHHHHHCCEECCCCCCCCCCCC   \n",
      "2  CCEEEECCCCCEEECCCCEHHHCECCCCCHHHCCCCCECCCCCCEH...   \n",
      "3  CCCEEEECCCECCCCECCHHHEEEECCCCCCCEHHHHHHHCCCEEC...   \n",
      "4  CHHHCCCCCEEEEEEEEECCCCCCCCCCCECCCEEEEEHHHHCCCC...   \n",
      "\n",
      "                                              ss_idx  \n",
      "0  [1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 3, 3, 3, 3, ...  \n",
      "1  [1, 2, 2, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...  \n",
      "2  [1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 1, ...  \n",
      "3  [1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, ...  \n",
      "4  [1, 3, 3, 3, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, ...  \n"
     ]
    }
   ],
   "source": [
    "print(df[['seq', 'seq_idx', 'sst3', 'ss_idx']].head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdb_id</th>\n",
       "      <th>seq_idx</th>\n",
       "      <th>ss_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5D8V</td>\n",
       "      <td>[1, 1, 13, 1, 12, 1, 18, 17, 1, 3, 3, 13, 17, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 3, 3, 3, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3NIR</td>\n",
       "      <td>[17, 17, 2, 2, 13, 16, 8, 18, 1, 15, 16, 12, 5...</td>\n",
       "      <td>[1, 2, 2, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5NW3</td>\n",
       "      <td>[11, 1, 9, 19, 18, 2, 9, 8, 2, 6, 21, 8, 21, 3...</td>\n",
       "      <td>[1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1UCS</td>\n",
       "      <td>[12, 9, 1, 16, 18, 18, 1, 12, 14, 10, 8, 13, 8...</td>\n",
       "      <td>[1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3X2M</td>\n",
       "      <td>[1, 17, 6, 6, 21, 18, 14, 14, 1, 17, 6, 14, 1,...</td>\n",
       "      <td>[1, 3, 3, 3, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pdb_id                                            seq_idx  \\\n",
       "0   5D8V  [1, 1, 13, 1, 12, 1, 18, 17, 1, 3, 3, 13, 17, ...   \n",
       "1   3NIR  [17, 17, 2, 2, 13, 16, 8, 18, 1, 15, 16, 12, 5...   \n",
       "2   5NW3  [11, 1, 9, 19, 18, 2, 9, 8, 2, 6, 21, 8, 21, 3...   \n",
       "3   1UCS  [12, 9, 1, 16, 18, 18, 1, 12, 14, 10, 8, 13, 8...   \n",
       "4   3X2M  [1, 17, 6, 6, 21, 18, 14, 14, 1, 17, 6, 14, 1,...   \n",
       "\n",
       "                                              ss_idx  \n",
       "0  [1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 3, 3, 3, 3, ...  \n",
       "1  [1, 2, 2, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...  \n",
       "2  [1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 1, ...  \n",
       "3  [1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, ...  \n",
       "4  [1, 3, 3, 3, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=['seq','sst3'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Spliting \n",
    "Now, most of the times we would just randomly split the data into train, validation and test sets. However, in this case we have to be careful. **Many proteins are evolutionary related and have same/similar sequences**. If highly similar proteins end up in both your training and testing sets, your model's test performance will be artificially inflated because it has essentially seen the answers before.\n",
    "\n",
    "To avoid this, I identified unique proteins (e.g., using PDB IDs or clustering similar sequences). I then split these unique identifiers into train, validation, and test groups (e.g., 70%/15%/15%)and then collected all the data rows corresponding to the identifiers in each group to form your final datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique proteins: 14557\n"
     ]
    }
   ],
   "source": [
    "#data split \n",
    "from sklearn.model_selection import train_test_split \n",
    "unique_protein_ids = df['pdb_id'].unique()\n",
    "print(f'Number of unique proteins: {len(unique_protein_ids)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training proteins: 10517\n",
      "Number of validation proteins: 1856\n",
      "Number of test proteins: 2184\n"
     ]
    }
   ],
   "source": [
    "train_ids, test_ids = train_test_split(unique_protein_ids, test_size=0.15, random_state=42)\n",
    "train_ids, val_ids = train_test_split(train_ids, test_size=0.15, random_state=42) \n",
    "\n",
    "print(f\"Number of training proteins: {len(train_ids)}\")\n",
    "print(f\"Number of validation proteins: {len(val_ids)}\")\n",
    "print(f\"Number of test proteins: {len(test_ids)}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 10898\n",
      "Number of validation samples: 1917\n",
      "Number of test samples: 2264\n"
     ]
    }
   ],
   "source": [
    "train_df = df[df['pdb_id'].isin(train_ids)].reset_index(drop=True)\n",
    "val_df = df[df['pdb_id'].isin(val_ids)].reset_index(drop=True)\n",
    "test_df = df[df['pdb_id'].isin(test_ids)].reset_index(drop=True)\n",
    "\n",
    "print(f\"Number of training samples: {len(train_df)}\")\n",
    "print(f\"Number of validation samples: {len(val_df)}\")\n",
    "print(f\"Number of test samples: {len(test_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "import torch.nn.functional as F \n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader,Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdb_id</th>\n",
       "      <th>seq_idx</th>\n",
       "      <th>ss_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5D8V</td>\n",
       "      <td>[1, 1, 13, 1, 12, 1, 18, 17, 1, 3, 3, 13, 17, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 3, 3, 3, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5NW3</td>\n",
       "      <td>[11, 1, 9, 19, 18, 2, 9, 8, 2, 6, 21, 8, 21, 3...</td>\n",
       "      <td>[1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pdb_id                                            seq_idx  \\\n",
       "0   5D8V  [1, 1, 13, 1, 12, 1, 18, 17, 1, 3, 3, 13, 17, ...   \n",
       "1   5NW3  [11, 1, 9, 19, 18, 2, 9, 8, 2, 6, 21, 8, 21, 3...   \n",
       "\n",
       "                                              ss_idx  \n",
       "0  [1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 3, 3, 3, 3, ...  \n",
       "1  [1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 1, ...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create custom dataset\n",
    "class ProteinSequenceDataset(Dataset):\n",
    "    def __init__(self,dataset):\n",
    "        self.seq = [torch.tensor(seq,dtype=torch.long) for seq in dataset['seq_idx'].tolist()]\n",
    "        self.labels = [torch.tensor(ss,dtype=torch.long) for ss in dataset['ss_idx'].tolist()] #secondary structure H,C,E \n",
    "        assert len(self.seq) == len(self.labels), \"Mismatch between number of sequences and labels\"\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return {'seq':self.seq[idx],'label':self.labels[idx]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 10898\n",
      "Sample sequence length: 83\n",
      "Sample label length: 83\n",
      "tensor([ 1,  1, 13,  1, 12,  1, 18, 17,  1,  3,  3, 13, 17,  1,  8,  1, 10,  9,\n",
      "        21, 12, 14,  3,  1, 17,  9, 16,  4, 15, 18,  1,  1,  1, 15, 13,  6, 10,\n",
      "        13, 13,  4,  4, 14,  7,  2,  1, 12,  2, 14,  5, 11, 14,  1, 12, 18,  6,\n",
      "         4,  6,  3, 19,  9,  6,  2, 14, 10,  5, 13,  6,  9, 10,  8, 12, 18, 12,\n",
      "         6, 19,  2,  1, 16, 19, 17, 10,  9,  1,  6])\n",
      "tensor([1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 1, 1, 2, 1, 1, 3, 3,\n",
      "        3, 1, 1, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 3, 3, 3, 1, 1, 3, 3, 3, 2, 1, 1,\n",
      "        2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1,\n",
      "        1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "train_dataset = ProteinSequenceDataset(train_df)\n",
    "val_dataset = ProteinSequenceDataset(val_df)\n",
    "test_dataset = ProteinSequenceDataset(test_df) \n",
    "\n",
    "print(\"Train dataset size:\", len(train_dataset))\n",
    "sample = train_dataset[0]\n",
    "print(f\"Sample sequence length: {len(sample['seq'])}\")\n",
    "print(f\"Sample label length: {len(sample['label'])}\")\n",
    "print(sample['seq'])\n",
    "print(sample['label']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch,pad_seq=PAD_ID_AA,pad_label=PAD_ID_SS):\n",
    "    seqs = [item['seq'] for item in batch]\n",
    "    ss = [item['label'] for item in batch]\n",
    "    padded_seqs = pad_sequence(seqs,batch_first=True,padding_value=pad_seq)\n",
    "    padded_ss = pad_sequence(ss,batch_first=True,padding_value=pad_label)\n",
    "    return padded_seqs,padded_ss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 180])\n",
      "torch.Size([4, 180])\n",
      "Example Padded Sequence: tensor([ 1,  1, 13,  1, 12,  1, 18, 17,  1,  3,  3, 13, 17,  1,  8,  1, 10,  9,\n",
      "        21, 12, 14,  3,  1, 17,  9, 16,  4, 15, 18,  1,  1,  1, 15, 13,  6, 10,\n",
      "        13, 13,  4,  4, 14,  7,  2,  1, 12,  2, 14,  5, 11, 14,  1, 12, 18,  6,\n",
      "         4,  6,  3, 19,  9,  6,  2, 14, 10,  5, 13,  6,  9, 10,  8, 12, 18, 12,\n",
      "         6, 19,  2,  1, 16, 19, 17, 10,  9,  1,  6,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "Example Padded Label: tensor([1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 1, 1, 2, 1, 1, 3, 3,\n",
      "        3, 1, 1, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 3, 3, 3, 1, 1, 3, 3, 3, 2, 1, 1,\n",
      "        2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1,\n",
      "        1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "dummy_batch = [train_dataset[i] for i in range(4)] \n",
    "padded_seqs_batch, padded_labels_batch = collate_fn(dummy_batch)\n",
    "print(padded_seqs_batch.shape)\n",
    "print(padded_labels_batch.shape)\n",
    "print(\"Example Padded Sequence:\", padded_seqs_batch[0])\n",
    "print(\"Example Padded Label:\", padded_labels_batch[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "##dataloaders \n",
    "train_loader = DataLoader(train_dataset,batch_size=8,shuffle=True,collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset,batch_size=8,shuffle=False,collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset,batch_size=8,shuffle=False,collate_fn=collate_fn) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 784])\n",
      "torch.Size([8, 784])\n"
     ]
    }
   ],
   "source": [
    "sample_batch = next(iter(train_loader))\n",
    "print(sample_batch[0].shape)\n",
    "print(sample_batch[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model \n",
    "I made a simple model with activations and 1D CNN blocks and get the logits as output. The model looks like this:\n",
    "\n",
    "Embedding -> Dropout -> (1D CNN -> RELU -> Dropout -> ) -> (1D CNN -> RELU -> Dropout -> ) -> (1D CNN -> RELU -> Dropout -> ) -> FC -> Logits \n",
    "\n",
    "\n",
    "- Embedding -> Dropout: The initial embedding is followed immediately by dropout \n",
    "- (...) -> (...) -> (...): The sequence of Convolutional layer (with a specific kernel size), ReLU activation, and Dropout repeats three times, once for each kernel size (3, 4, and 5).\n",
    "- FC -> Logits: The final fully connected layer maps the features to logits. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## model \n",
    "class SecondaryStructurePredictor(nn.Module):\n",
    "    def __init__(self,aa_vocab_size,num_classes_ss,embed_dim,cnn_channels,kernel_sizes,dropout_rate,pad_idx_aa):\n",
    "        super().__init__() \n",
    "        self.pad_idx_aa = pad_idx_aa\n",
    "        self.embed_dim = embed_dim \n",
    "        self.cnn_channels = cnn_channels \n",
    "\n",
    "        #1. Embedding layer \n",
    "        self.embeding = nn.Embedding(\n",
    "            num_embeddings = aa_vocab_size,\n",
    "            embedding_dim = embed_dim,\n",
    "            padding_idx = pad_idx_aa\n",
    "        )\n",
    "\n",
    "        #2.CNN layer-1d CNN \n",
    "        self.conv_layers = nn.ModuleList()\n",
    "        in_channels = embed_dim \n",
    "        for i,k_size in enumerate(kernel_sizes):\n",
    "            conv_layer = nn.Conv1d(\n",
    "                in_channels = in_channels,\n",
    "                out_channels = cnn_channels,\n",
    "                kernel_size = k_size,\n",
    "                padding = 'same'\n",
    "            )\n",
    "            self.conv_layers.append(conv_layer)\n",
    "            in_channels = cnn_channels\n",
    "        \n",
    "        ##Activation and dropout \n",
    "        self.activation = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        #output layer \n",
    "        self.fc_out = nn.Linear(\n",
    "            cnn_channels,\n",
    "            num_classes_ss\n",
    "        )\n",
    "    \n",
    "    #forward pass\n",
    "    def forward(self,x):\n",
    "        #apply embedding \n",
    "        embedded = self.dropout(self.embeding(x))\n",
    "        conv_input = embedded.permute(0,2,1) #(batch_size,embed_dim,seq_len) \n",
    "        #apply CNN layers \n",
    "        conv_output = conv_input \n",
    "        for conv_layer in self.conv_layers:\n",
    "            conv_output = self.dropout(self.activation(conv_layer(conv_output))) #(batch,embed_dim,seq_len) --> (batch,out_channels,seq_len)\n",
    "        output_features = conv_output.permute(0,2,1) #(batch,out_channels,seq_len) --> (batch,seq_len,out_channels)\n",
    "\n",
    "        #final layers\n",
    "        logits = self.fc_out(output_features) #(batch,seq_len,num_classes_ss) \n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Hyperparams\n",
    "VOCAB_AA = len(aa_list_pad)\n",
    "NUM_CLASSES_SS = len(ss_list_pad) \n",
    "EMBEDDING_DIM = 100 \n",
    "CNN_CHANNELS = 128 \n",
    "KERNEL_SIZES = [3, 4, 5] #STACK 3 CONV1D LAYERS\n",
    "DROPOUT_RATE = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SecondaryStructurePredictor(\n",
       "  (embeding): Embedding(22, 100, padding_idx=0)\n",
       "  (conv_layers): ModuleList(\n",
       "    (0): Conv1d(100, 128, kernel_size=(3,), stride=(1,), padding=same)\n",
       "    (1): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=same)\n",
       "    (2): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=same)\n",
       "  )\n",
       "  (activation): ReLU()\n",
       "  (dropout): Dropout(p=0.4, inplace=False)\n",
       "  (fc_out): Linear(in_features=128, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "print(device) \n",
    "\n",
    "model = SecondaryStructurePredictor(VOCAB_AA, NUM_CLASSES_SS, EMBEDDING_DIM, CNN_CHANNELS, KERNEL_SIZES, DROPOUT_RATE,pad_idx_aa=PAD_ID_AA).to(device) \n",
    "model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input shape: torch.Size([8, 483])\n",
      "Output logits shape: torch.Size([8, 483, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BiswanathSaha\\miniconda3\\envs\\stable\\lib\\site-packages\\torch\\nn\\modules\\conv.py:370: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\Convolution.cpp:1037.)\n",
      "  return F.conv1d(\n"
     ]
    }
   ],
   "source": [
    "#test a single forward pass\n",
    "dummy_seq_batch, _ = next(iter(train_loader))\n",
    "dummy_seq_batch = dummy_seq_batch.to(device)\n",
    "print(\"\\nInput shape:\", dummy_seq_batch.shape) \n",
    "\n",
    "with torch.no_grad(): # No need to calculate gradients for testing\n",
    "    model.eval() # Set model to evaluation mode\n",
    "    output_logits = model(dummy_seq_batch)\n",
    "    model.train() # Set model back to training mode\n",
    "\n",
    "print(\"Output logits shape:\", output_logits.shape) # Should be [batch_size, seq_len, num_classes_sst3] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_ID_SS) #ss \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score \n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def train_epoch(model, data_loader, criterion, optimizer, device):\n",
    "    \"\"\"Trains the model for one epoch.\"\"\"\n",
    "    model.train() # Set model to training mode\n",
    "    total_loss = 0.0\n",
    "    # Assuming collate_fn returns (seqs, labels) tuple\n",
    "    for seqs, labels in data_loader:\n",
    "        seqs = seqs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(seqs) # Shape: (batch, seq_len, num_classes)\n",
    "\n",
    "        # Reshape for criterion (e.g., CrossEntropyLoss)\n",
    "        # Assumes criterion expects (N, C) and (N,) and handles ignore_index\n",
    "        loss = criterion(outputs.view(-1, outputs.shape[-1]), labels.view(-1))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(data_loader)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, data_loader, criterion, device, PAD_ID_SS):\n",
    "    \"\"\"Evaluates the model on a given dataset.\"\"\"\n",
    "    model.eval() # Set model to evaluation mode\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_items = 0\n",
    "\n",
    "    with torch.no_grad(): # Disable gradient calculations\n",
    "        # Assuming collate_fn returns (seqs, labels) tuple\n",
    "        for seqs, labels in data_loader:\n",
    "            seqs = seqs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(seqs) # Shape: (batch, seq_len, num_classes)\n",
    "\n",
    "            # Calculate loss (criterion handles ignore_index)\n",
    "            loss = criterion(outputs.view(-1, outputs.shape[-1]), labels.view(-1))\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Calculate accuracy, ignoring padding\n",
    "            preds = torch.argmax(outputs, dim=-1) # Shape: (batch, seq_len)\n",
    "            mask = (labels != PAD_ID_SS) # Create mask for non-padding tokens\n",
    "\n",
    "            correct_in_batch = (preds[mask] == labels[mask]).sum().item()\n",
    "            items_in_batch = mask.sum().item()\n",
    "\n",
    "            total_correct += correct_in_batch\n",
    "            total_items += items_in_batch\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    # Handle potential division by zero if data_loader is empty or all items are padded\n",
    "    avg_acc = (total_correct / total_items) if total_items > 0 else 0\n",
    "\n",
    "    return avg_loss, avg_acc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26c61f3a0c44472da69cfe7c7175e6e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 0.8605, Val Loss: 0.7898, Val Accuracy: 0.6508\n",
      "Epoch 2/100, Train Loss: 0.8175, Val Loss: 0.7802, Val Accuracy: 0.6562\n",
      "Epoch 3/100, Train Loss: 0.8102, Val Loss: 0.7836, Val Accuracy: 0.6545\n",
      "Epoch 4/100, Train Loss: 0.8060, Val Loss: 0.7803, Val Accuracy: 0.6560\n",
      "Epoch 5/100, Train Loss: 0.8042, Val Loss: 0.7728, Val Accuracy: 0.6598\n",
      "Epoch 6/100, Train Loss: 0.8027, Val Loss: 0.7710, Val Accuracy: 0.6620\n",
      "Epoch 7/100, Train Loss: 0.8001, Val Loss: 0.7694, Val Accuracy: 0.6618\n",
      "Epoch 8/100, Train Loss: 0.7993, Val Loss: 0.7984, Val Accuracy: 0.6443\n",
      "Epoch 9/100, Train Loss: 0.7985, Val Loss: 0.7681, Val Accuracy: 0.6634\n",
      "Epoch 10/100, Train Loss: 0.7978, Val Loss: 0.7675, Val Accuracy: 0.6634\n",
      "Epoch 11/100, Train Loss: 0.7978, Val Loss: 0.7689, Val Accuracy: 0.6646\n",
      "Epoch 12/100, Train Loss: 0.7971, Val Loss: 0.7690, Val Accuracy: 0.6634\n",
      "Epoch 13/100, Train Loss: 0.7955, Val Loss: 0.7668, Val Accuracy: 0.6645\n",
      "Epoch 14/100, Train Loss: 0.7958, Val Loss: 0.7648, Val Accuracy: 0.6653\n",
      "Epoch 15/100, Train Loss: 0.7947, Val Loss: 0.7640, Val Accuracy: 0.6647\n",
      "Epoch 16/100, Train Loss: 0.7953, Val Loss: 0.7699, Val Accuracy: 0.6648\n",
      "Epoch 17/100, Train Loss: 0.7934, Val Loss: 0.7705, Val Accuracy: 0.6631\n",
      "Epoch 18/100, Train Loss: 0.7943, Val Loss: 0.7671, Val Accuracy: 0.6618\n",
      "Epoch 19/100, Train Loss: 0.7935, Val Loss: 0.7645, Val Accuracy: 0.6653\n",
      "Epoch 20/100, Train Loss: 0.7933, Val Loss: 0.7659, Val Accuracy: 0.6634\n",
      "Epoch 21/100, Train Loss: 0.7925, Val Loss: 0.7663, Val Accuracy: 0.6649\n",
      "Epoch 22/100, Train Loss: 0.7932, Val Loss: 0.7672, Val Accuracy: 0.6639\n",
      "Epoch 23/100, Train Loss: 0.7920, Val Loss: 0.7649, Val Accuracy: 0.6658\n",
      "Epoch 24/100, Train Loss: 0.7909, Val Loss: 0.7677, Val Accuracy: 0.6626\n",
      "Epoch 25/100, Train Loss: 0.7908, Val Loss: 0.7638, Val Accuracy: 0.6662\n",
      "Epoch 26/100, Train Loss: 0.7913, Val Loss: 0.7622, Val Accuracy: 0.6660\n",
      "Epoch 27/100, Train Loss: 0.7911, Val Loss: 0.7722, Val Accuracy: 0.6612\n",
      "Epoch 28/100, Train Loss: 0.7905, Val Loss: 0.7616, Val Accuracy: 0.6659\n",
      "Epoch 29/100, Train Loss: 0.7908, Val Loss: 0.7621, Val Accuracy: 0.6660\n",
      "Epoch 30/100, Train Loss: 0.7898, Val Loss: 0.7602, Val Accuracy: 0.6662\n",
      "Epoch 31/100, Train Loss: 0.7896, Val Loss: 0.7632, Val Accuracy: 0.6662\n",
      "Epoch 32/100, Train Loss: 0.7886, Val Loss: 0.7659, Val Accuracy: 0.6632\n",
      "Epoch 33/100, Train Loss: 0.7885, Val Loss: 0.7646, Val Accuracy: 0.6660\n",
      "Epoch 34/100, Train Loss: 0.7891, Val Loss: 0.7628, Val Accuracy: 0.6647\n",
      "Epoch 35/100, Train Loss: 0.7887, Val Loss: 0.7621, Val Accuracy: 0.6656\n",
      "Epoch 36/100, Train Loss: 0.7885, Val Loss: 0.7659, Val Accuracy: 0.6638\n",
      "Epoch 37/100, Train Loss: 0.7875, Val Loss: 0.7606, Val Accuracy: 0.6656\n",
      "Epoch 38/100, Train Loss: 0.7874, Val Loss: 0.7618, Val Accuracy: 0.6656\n",
      "Epoch 39/100, Train Loss: 0.7868, Val Loss: 0.7656, Val Accuracy: 0.6648\n",
      "Epoch 40/100, Train Loss: 0.7869, Val Loss: 0.7691, Val Accuracy: 0.6642\n",
      "Epoch 41/100, Train Loss: 0.7871, Val Loss: 0.7624, Val Accuracy: 0.6660\n",
      "Epoch 42/100, Train Loss: 0.7859, Val Loss: 0.7611, Val Accuracy: 0.6653\n",
      "Epoch 43/100, Train Loss: 0.7869, Val Loss: 0.7610, Val Accuracy: 0.6664\n",
      "Epoch 44/100, Train Loss: 0.7858, Val Loss: 0.7619, Val Accuracy: 0.6647\n",
      "Epoch 45/100, Train Loss: 0.7859, Val Loss: 0.7612, Val Accuracy: 0.6664\n",
      "Epoch 46/100, Train Loss: 0.7860, Val Loss: 0.7606, Val Accuracy: 0.6655\n",
      "Epoch 47/100, Train Loss: 0.7857, Val Loss: 0.7629, Val Accuracy: 0.6648\n",
      "Epoch 48/100, Train Loss: 0.7857, Val Loss: 0.7637, Val Accuracy: 0.6661\n",
      "Epoch 49/100, Train Loss: 0.7844, Val Loss: 0.7614, Val Accuracy: 0.6659\n",
      "Epoch 50/100, Train Loss: 0.7844, Val Loss: 0.7605, Val Accuracy: 0.6663\n",
      "Epoch 51/100, Train Loss: 0.7845, Val Loss: 0.7663, Val Accuracy: 0.6631\n",
      "Epoch 52/100, Train Loss: 0.7844, Val Loss: 0.7644, Val Accuracy: 0.6643\n",
      "Epoch 53/100, Train Loss: 0.7842, Val Loss: 0.7586, Val Accuracy: 0.6667\n",
      "Epoch 54/100, Train Loss: 0.7843, Val Loss: 0.7591, Val Accuracy: 0.6673\n",
      "Epoch 55/100, Train Loss: 0.7840, Val Loss: 0.7610, Val Accuracy: 0.6654\n",
      "Epoch 56/100, Train Loss: 0.7833, Val Loss: 0.7607, Val Accuracy: 0.6668\n",
      "Epoch 57/100, Train Loss: 0.7833, Val Loss: 0.7623, Val Accuracy: 0.6676\n",
      "Epoch 58/100, Train Loss: 0.7832, Val Loss: 0.7605, Val Accuracy: 0.6657\n",
      "Epoch 59/100, Train Loss: 0.7836, Val Loss: 0.7586, Val Accuracy: 0.6671\n",
      "Epoch 60/100, Train Loss: 0.7831, Val Loss: 0.7608, Val Accuracy: 0.6661\n",
      "Epoch 61/100, Train Loss: 0.7822, Val Loss: 0.7585, Val Accuracy: 0.6669\n",
      "Epoch 62/100, Train Loss: 0.7831, Val Loss: 0.7606, Val Accuracy: 0.6659\n",
      "Epoch 63/100, Train Loss: 0.7830, Val Loss: 0.7594, Val Accuracy: 0.6671\n",
      "Epoch 64/100, Train Loss: 0.7830, Val Loss: 0.7584, Val Accuracy: 0.6669\n",
      "Epoch 65/100, Train Loss: 0.7826, Val Loss: 0.7584, Val Accuracy: 0.6671\n",
      "Epoch 66/100, Train Loss: 0.7821, Val Loss: 0.7584, Val Accuracy: 0.6673\n",
      "Epoch 67/100, Train Loss: 0.7823, Val Loss: 0.7580, Val Accuracy: 0.6669\n",
      "Epoch 68/100, Train Loss: 0.7822, Val Loss: 0.7564, Val Accuracy: 0.6670\n",
      "Epoch 69/100, Train Loss: 0.7817, Val Loss: 0.7584, Val Accuracy: 0.6677\n",
      "Epoch 70/100, Train Loss: 0.7826, Val Loss: 0.7680, Val Accuracy: 0.6620\n",
      "Epoch 71/100, Train Loss: 0.7814, Val Loss: 0.7629, Val Accuracy: 0.6667\n",
      "Epoch 72/100, Train Loss: 0.7822, Val Loss: 0.7586, Val Accuracy: 0.6676\n",
      "Epoch 73/100, Train Loss: 0.7818, Val Loss: 0.7586, Val Accuracy: 0.6669\n",
      "Epoch 74/100, Train Loss: 0.7822, Val Loss: 0.7584, Val Accuracy: 0.6673\n",
      "Epoch 75/100, Train Loss: 0.7821, Val Loss: 0.7587, Val Accuracy: 0.6679\n",
      "Epoch 76/100, Train Loss: 0.7822, Val Loss: 0.7556, Val Accuracy: 0.6678\n",
      "Epoch 77/100, Train Loss: 0.7817, Val Loss: 0.7601, Val Accuracy: 0.6657\n",
      "Epoch 78/100, Train Loss: 0.7822, Val Loss: 0.7590, Val Accuracy: 0.6663\n",
      "Epoch 79/100, Train Loss: 0.7815, Val Loss: 0.7596, Val Accuracy: 0.6658\n",
      "Epoch 80/100, Train Loss: 0.7819, Val Loss: 0.7577, Val Accuracy: 0.6675\n",
      "Epoch 81/100, Train Loss: 0.7818, Val Loss: 0.7584, Val Accuracy: 0.6668\n",
      "Epoch 82/100, Train Loss: 0.7819, Val Loss: 0.7573, Val Accuracy: 0.6679\n",
      "Epoch 83/100, Train Loss: 0.7812, Val Loss: 0.7572, Val Accuracy: 0.6681\n",
      "Epoch 84/100, Train Loss: 0.7820, Val Loss: 0.7634, Val Accuracy: 0.6640\n",
      "Epoch 85/100, Train Loss: 0.7820, Val Loss: 0.7668, Val Accuracy: 0.6633\n",
      "Epoch 86/100, Train Loss: 0.7815, Val Loss: 0.7564, Val Accuracy: 0.6681\n",
      "Epoch 87/100, Train Loss: 0.7820, Val Loss: 0.7590, Val Accuracy: 0.6658\n",
      "Epoch 88/100, Train Loss: 0.7820, Val Loss: 0.7562, Val Accuracy: 0.6673\n",
      "Epoch 89/100, Train Loss: 0.7809, Val Loss: 0.7576, Val Accuracy: 0.6675\n",
      "Epoch 90/100, Train Loss: 0.7812, Val Loss: 0.7583, Val Accuracy: 0.6679\n",
      "Epoch 91/100, Train Loss: 0.7823, Val Loss: 0.7583, Val Accuracy: 0.6675\n",
      "Epoch 92/100, Train Loss: 0.7811, Val Loss: 0.7581, Val Accuracy: 0.6673\n",
      "Epoch 93/100, Train Loss: 0.7814, Val Loss: 0.7583, Val Accuracy: 0.6676\n",
      "Epoch 94/100, Train Loss: 0.7811, Val Loss: 0.7586, Val Accuracy: 0.6674\n",
      "Epoch 95/100, Train Loss: 0.7815, Val Loss: 0.7589, Val Accuracy: 0.6672\n",
      "Epoch 96/100, Train Loss: 0.7805, Val Loss: 0.7584, Val Accuracy: 0.6678\n",
      "Epoch 97/100, Train Loss: 0.7813, Val Loss: 0.7572, Val Accuracy: 0.6674\n",
      "Epoch 98/100, Train Loss: 0.7802, Val Loss: 0.7590, Val Accuracy: 0.6662\n",
      "Epoch 99/100, Train Loss: 0.7805, Val Loss: 0.7572, Val Accuracy: 0.6673\n",
      "Epoch 100/100, Train Loss: 0.7808, Val Loss: 0.7575, Val Accuracy: 0.6674\n",
      "Training complete\n"
     ]
    }
   ],
   "source": [
    "epochs = 100 \n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "for epoch in tqdm(range(epochs)): \n",
    "    train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    val_loss, val_accuracy = evaluate_model(model, val_loader, criterion, device,PAD_ID_SS)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "print(\"Training complete\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Val Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"secondary_structure_model_epoch_100.pth\") # Save the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss:  0.7880874049724765\n",
      "Average val loss:  0.7632709107870859\n",
      "Average val accuracy:  0.6650354963232656\n"
     ]
    }
   ],
   "source": [
    "print('Average train loss: ', np.mean(train_losses))\n",
    "print('Average val loss: ', np.mean(val_losses))\n",
    "print('Average val accuracy: ', np.mean(val_accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation\n",
    "1. Model does learn from the training data.\n",
    "2. No Clear overfitting.\n",
    "3. Performance plateaus after towards the end of 100 epochs.\n",
    "4. Average per residue accuracy on validation set is around 60%.  Decent result, but not outstanding. of course the model is not that complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on Test Set...\n",
      "Test Loss: 0.7576\n",
      "Test Accuracy: 0.6678\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating on Test Set...\")\n",
    "test_loss, test_acc = evaluate_model(model, test_loader, criterion, device, PAD_ID_SS)\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def predict_compare_sample(model,dataset,idx_to_aa,idx_to_ss,device,sample_idx=None):\n",
    "    if sample_idx is None:\n",
    "        sample_idx = random.randint(0,len(dataset)-1)\n",
    "    elif sample_idx >= len(dataset):\n",
    "        print(f\"Warning: sample_idx {sample_idx} is out of bounds for dataset size {len(dataset)}. Using index 0.\")\n",
    "        sample_idx = 0\n",
    "    \n",
    "    item = dataset[sample_idx]\n",
    "    seq_tensor = item['seq']\n",
    "    label_tensor = item['label']\n",
    "    seq_len = len(seq_tensor)\n",
    "\n",
    "    model_inputs = seq_tensor.unsqueeze(0).to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        model_outputs = model(model_inputs)\n",
    "    \n",
    "    pred_tensor = torch.argmax(model_outputs, dim=-1) \n",
    "    pred_tensor = pred_tensor.squeeze(0).cpu().numpy()\n",
    "    \n",
    "    original_seq = \"\".join([idx_to_aa.get(idx.item(),'?') for idx in seq_tensor])\n",
    "    actual_ss = \"\".join([idx_to_ss.get(idx.item(),'?') for idx in label_tensor])\n",
    "    predicted_ss = \"\".join([idx_to_ss.get(idx.item(),'?') for idx in pred_tensor])\n",
    "\n",
    "    mismatches = \"\"\n",
    "    wrong_idx = []\n",
    "    for i in range(seq_len):\n",
    "        if label_tensor[i] == pred_tensor[i]:\n",
    "            mismatches += \" \"\n",
    "        else:\n",
    "            mismatches += \"X\"\n",
    "            wrong_idx.append(i)\n",
    "    print(f\"--- Sample Index: {sample_idx} ---\")\n",
    "    print(f\"Length: {seq_len}\")\n",
    "    print(f\"Input Sequence: {original_seq}\")\n",
    "    print(f\"Actual SS     : {actual_ss}\")\n",
    "    print(f\"Predicted SS  : {predicted_ss}\")\n",
    "    print(\"-\" * (len(original_seq) + 18)) \n",
    "\n",
    "    correct_preds = (label_tensor == pred_tensor).sum().item()\n",
    "    accuracy = correct_preds / seq_len\n",
    "    print(f\"Accuracy: {accuracy:.4f}\") \n",
    "\n",
    "    if wrong_idx:\n",
    "        print(f\"Incorrect prediction indices: {wrong_idx}\")\n",
    "    else:\n",
    "        print(\"All predictions correct for this sample.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Sample Index: 0 ---\n",
      "Length: 133\n",
      "Input Sequence: GMSNKFLGTWKLVSSENFDDYMKALGVGLATRKLGNLAKPTVIISKKGDIITIRTESTFKNTEISFKLGQEFEETTADNRKTKSIVTLQRGSLNQVQRWDGKETTIKRKLVNGKMVAEXKMKGVVXTRIYEKV\n",
      "Actual SS     : CCCHHHCEEEEEEEEECHHHHHHHCCCCHHHHHHHHHCCCEEEEEEECCEEEEEEECCCCEEEEEECCCCCEEEECCCCCEEEEEEEEECCEEEEEEEECCEEEEEEEEEECCEEEEEEEECCEEEEEEEEEC\n",
      "Predicted SS  : CCCCCHECEEEEECCCCHHHHHHHCCCCHHHHHHCCCCCCEEEEECCCCEEEEEECCCCCCCEEEEECCHHHHHCCCCCCCCCEEEEEECCCHHHHEEECCCEEHHHHHHECCHHEHHHHHCCEEEHHHHCCC\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Accuracy: 0.6241\n",
      "Incorrect prediction indices: [3, 4, 6, 7, 13, 14, 15, 34, 35, 36, 45, 46, 55, 60, 61, 66, 69, 70, 71, 72, 73, 74, 80, 81, 82, 91, 92, 93, 94, 95, 101, 104, 105, 106, 107, 108, 109, 113, 114, 116, 117, 118, 119, 120, 126, 127, 128, 129, 130, 131]\n"
     ]
    }
   ],
   "source": [
    "predict_compare_sample(model,test_dataset,aa_idx_to_aa,ss_idx_to_ss,device,sample_idx=0)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I will try to improve the model's performance with hyperparameter tuning with wandb."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stable",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
